{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerful algorithm widely used (_at least at the time of the video_) in both industry and academia are Support Vector Machines (SVM). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start to understand SVM starting from the sigmoid activation function of logistic regression. \n",
    "\n",
    "$h_{\\theta}(x) = \\frac{1}{1+e^{-\\theta^T x}} $\n",
    "\n",
    "For a single example, our cost function will be: \n",
    "\n",
    "$Cost(h_{\\theta}(x), y) = -ylog(h_{\\theta}(x)) - (1-y)log(1-h_{\\theta}(x))$\n",
    "\n",
    "\n",
    "### Graphical intuition\n",
    "\n",
    "**Part 1**ï¼š $y = 1$\n",
    "\n",
    "$Cost(h_{\\theta}(x), y) = -log(h_{\\theta}(x)) = -log\\frac{1}{1+e^{-\\theta^T x}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will modify this function and _split_ it in two linear parts (flat for $z > 1$ and straight line otherwise). \n",
    "\n",
    "$Cost_1(z)$\n",
    "\n",
    "![SVM Graphical Intuition 1](Figures/SVM_Graph_1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**: $y = 0$\n",
    "\n",
    "$Cost(h_{\\theta}(x), y) = -log(1-h_{\\theta}(x)) = -log(1 - \\frac{1}{1+e^{-\\theta^T x}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now _split_ it in a similar way, this time with a theshold placed at $z = -1$:\n",
    "\n",
    "$Cost_0(z)$\n",
    "\n",
    "![SVM Graphical Intuition 2](Figures/SVM_Graph_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "\n",
    "$ min_{\\theta} [\\sum_{i=1}^m y^{(i)} cost_1{\\theta}x^{(i)} + (1-y^{(i)}) cost_0(1- h_{\\theta}x^{(i)})] + \\frac{1}{2} \\sum_{j=1}^n \\theta^2_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notation change**: for log reg our cost function structure would look something like this:\n",
    "\n",
    "$ A + \\lambda B$ (lambda trying to regularize / _balance_ B)\n",
    "\n",
    "By convention, with SVM we will change to:\n",
    "\n",
    "$ C A + B$ \n",
    "\n",
    "In the end, it's just a different way to control the trade-off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Margin Intuition\n",
    "\n",
    "For SVM:\n",
    "\n",
    "If $y = 1$ we want $\\theta^T x \\ge 1$ (not just $\\ge 0$)  \n",
    "If $y = 0$ we want $\\theta^T x \\le -1$ (not just $\\le 0$)\n",
    "\n",
    "This means that we have an extra **margin** compared to logistic regression, since our function it will require more extreme cases to classify a value as 1 or 0. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
