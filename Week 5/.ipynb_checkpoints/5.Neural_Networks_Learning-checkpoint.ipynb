{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks: Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will learn how to fit the parameters of the neural network given a training set. \n",
    "\n",
    "In our (classification) problems, we will be dealing with either:\n",
    "\n",
    "1. Binary classification (1 output unit)\n",
    "2. Multi-class classification (k output units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "Our neural network cost function is a generalization of the logistic regression cost function:\n",
    "\n",
    "$J(\\Theta) = -\\frac{1}{m}[\\sum_{i=1}^m \\sum_{k=1}^K y_k^{(i)} log(h_\\Theta(x^{(i)}))_k + (1-y_k^{(i)})log(1-(h_\\Theta(x^{(i)}))_k)] + \\frac{\\lambda}{2m} \\sum_{l=1}^{L-1} \\sum_{i=1}^{s_l} \\sum_{j=1}^{s_{l+1}} (\\Theta_{ji}^{(l)})^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "\n",
    "1. The double sum adds up the logistic regression costs calculated for each cell in the output layer;\n",
    "2. The triple sum adds up the squares of all the individual $\\Theta$s in the entire network;\n",
    "3. the i in the triple sum does **not** refer to training example i;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation algorithm\n",
    "\n",
    "Just as a remainder, what we did in the previous section (Week 4) was **forward propagation**. Starting from the first layer all the way to the output layer.\n",
    "\n",
    "**Intuition**: for each node $j$ in layer $l$ we will calculate the _error_ $\\delta_j^{(l)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The backpropagation algorithm works as follows:\n",
    "\n",
    "Given a training set $\\{ (x^{(1)}, x^{(2)} ) \\cdots (x^{(m)}, y^{(m)}) \\}$\n",
    "\n",
    "1. $\\Delta^{(l)}_ij = 0$ for all $(l,i,j)$\n",
    "\n",
    "2. \n",
    "\n",
    "3. \n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
