{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggests, anomaly detection algorithms detect when a data point deviate substantially from the rest. \n",
    "\n",
    "More formally, we specify a paramter $\\epsilon$ and **flag** our data point if $p(x_{test}) < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "To develop our anomaly detection algorithm, we will assume that our $x_i$ are distributed normally:\n",
    "\n",
    "$x_i \\sim N(\\mu, \\sigma^2)$ \n",
    "\n",
    "The next steps are:\n",
    "\n",
    "1. Choose features $x_i$ that may characterize anomalous examples  \n",
    "2. Fit paramters \n",
    "\n",
    "$\\mu_i = \\frac{1}{m} \\sum^m_{i =1} x_j^{(i)}$  \n",
    "$\\sigma_j^2 = \\frac{1}{m} \\sum^m_{i =1} (x_j^{(i)} - \\mu_j )^2$\n",
    "\n",
    "3. Given new example $x$ compute $p(x)$:\n",
    "\n",
    "$p(x) = \\prod_{j = i}^n p(x_j; \\mu_j; \\sigma_j^2) = \\prod_{j = i}^n \\frac{1}{\\sqrt{2\\pi}\\sigma_j} exp (- \\frac{(x_j - \\mu_j )^2}{2\\sigma_j^2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating anomaly detection systems\n",
    "\n",
    "In order to evaluate our models and take decisions on whether / how to improve them, we will resort to using labeled data and treat it as a supervised learning problem. \n",
    "\n",
    "A good _rule of thumb_ data split to evaluate an algorithm an algorithm would be:\n",
    "\n",
    "* **Training set**: 60% only normal data\n",
    "* **Cross-validaton**: 20% of normal data + 50% of anomalous data\n",
    "* **Test**: 20% of normal data + 50% of anomalous data\n",
    "\n",
    "Now, we can evaluate it by:\n",
    "\n",
    "1. Fitting model $p(x)$ on training set\n",
    "2. On a CV / test example, predict y if $p(x) < \\epsilon$ (anomaly) and y = 0 otherwise\n",
    "3. Using possible evaluation metrics:\n",
    "        - True pos, false pos, true neg, false neg\n",
    "        - Precision / Recall\n",
    "        - F1 score\n",
    "        \n",
    "**Note**: We can also choose $\\epsilon$ based on CV set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting question: why don't we use supervised learning (e.g. LR) directly on anomaly detection problems?\n",
    "\n",
    "Some of the reasons might be:\n",
    "\n",
    "* Strong imbalance in number of negative (normal) vs. positive examples in anomaly detection\n",
    "* Hard to learn what constitute a positive example (anomaly) as new anomaly can be substantially different from previous ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Altough our algorithms may work well even with non-gaussian features, it is usually good practice to try and transform features to make them closer to a normal distribution. \n",
    "\n",
    "It is also useeful to perform **error analysis** by looking at individual instances of anomalies to understand how to transform them into features which are more easily characterized as anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Gaussian (Normal) Distribution\n",
    "\n",
    "Sometimes our model fails to recognize anomalies simply because of the limitations of our gaussian distribution. Computing $p(x)$ one by one can lead to the wrong outcomes, therefore we can solve the problem by computing $p(x)$ all at once. \n",
    "\n",
    "This way, we can also detect anomalies for correlated variables. \n",
    "\n",
    "The algorithm is similar to what we have seen before:\n",
    "\n",
    "1. Fit model $p(x)$ by setting $\\mu$ and $\\sigma$\n",
    "2. Given a new example $x$, compute:\n",
    "\n",
    "$p(x) = \\frac {1}{ (2\\pi)^{\\frac{n}{2}} |\\Sigma|^{\\frac{1}{2}} } exp (-\\frac{1}{2}(x- \\mu)^T \\Sigma ^ {-1} (x- \\mu))  $\n",
    "\n",
    "3. Flag an anomaly if $p(x) < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Single variable Gaussian distribution models are just a subset of multivariate models where the covariance matrix $\\Sigma$ is 0 expect for the diagonal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender Systems\n",
    "\n",
    "**Problem formulation**: how do we estimate unknown values for certain agents based on values given by other agents?  \n",
    "**Example**: movie ratings (1 to 5)  \n",
    "**Notation**: $r(i,j) = 1$ if movie has been rated - $y^{(i,j)}$ = rating given by user $j$ to movie $i$ (if rated)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) One potential technique to address this problem is **content-based recommender systems**: \n",
    "\n",
    "1. Assign a score to every movie according to certain parameters (e.g. romance, action, etc.) so we can represent each movie as a feature vector $x^i$\n",
    "2. Learn a parameter $\\Theta^{(j)}$ for each user  \n",
    "3. Predict $y^{(i,j)}$ as $(\\Theta^{(j)})^T x^{(i)}$\n",
    "\n",
    "**Note**: this is not different (also mathematically) from applying a linear regression for each user. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Another potential approach is called **collaborative filtering**, where we don't even need features:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
