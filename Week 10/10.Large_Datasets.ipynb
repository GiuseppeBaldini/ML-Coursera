{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Large Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we know that in many cases more data = more accurate algorithms, as a first step it is always worth checking if good results can already be accomplished with less data. \n",
    "\n",
    "A good method to check this would be plotting the learning curve (error as function of training size) and check for convergence. If that's not happening, we are likely in a low bias situation, which makes us more confident that adding data will improve our algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent \n",
    "\n",
    "The gradient descent we saw in previous sections is also called **batch gradient descent**. However, a different approach may be using **stochastic gradient descent**, working as follows:\n",
    "\n",
    "1. Randomly reorder training examples\n",
    "2. Go through training examples _individually_ (without need to sum over all training examples, like batch GD does) \n",
    "\n",
    "**Note**: this means that SGD cost may not strictly decrease over type, and will likely \"random walk\" to get close to the global minimum.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch Gradient Descent\n",
    "\n",
    "Mini-batch GD lies in between our previous batch and stochastic flavours. The comparison would look something like this:\n",
    "\n",
    "* Batch: all $m$ examples in each iteration\n",
    "* Stochastic: 1 example in each iteration\n",
    "* Mini-batch: $b$ examples in each iteration\n",
    "\n",
    "**Note**: computationally, the advantage of mini-batch comes from vectorization allowing for parallel computation, something that is not possible (or is limited) for stochastic GD. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence\n",
    "\n",
    "A useful approach with regards to learning rate $\\alpha$ is to let it slowly decrease over time for better covergence. To do so, we can have $\\alpha$ being inversely proportional to the iteration number：\n",
    "\n",
    "$\\alpha = \\frac{const1}{\\text{iteration number + const2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MapReduce\n",
    "\n",
    "MapReduce is a programming model which allow us to run distributed (parallel）computation for large dataset. \n",
    "\n",
    "To illustrate this with a simple example, imagine a dataset of n examples. What MapReduce would do is:\n",
    "\n",
    "1. Split the dataset to m machines / worker nodes (each processing n / m examples)  \n",
    "2. Each node would run the same operation on their portion of the dataset\n",
    "3. Once finished, the results of these operations are sent to a central server / master node \n",
    "4. The \"pieces\" are put back together\n",
    "4. The master node computes our gradient descent on this aggregate\n",
    "\n",
    "**Note 1**: the key question to evaluate if MapReduce can be applied to our specific problem is: can this algorithm be expressed as computing sums of functions over the training set? \n",
    "\n",
    "**Note 2**：this approach can also be used on a single (multi-core) machine.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
