{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name suggests, anomaly detection algorithms detect when a data point deviate substantially from the rest. \n",
    "\n",
    "More formally, we specify a paramter $\\epsilon$ and **flag** our data point if $p(x_{test}) < \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "To develop our anomaly detection algorithm, we will assume that our $x_i$ are distributed normally:\n",
    "\n",
    "$x_i \\sim N(\\mu, \\sigma^2)$ \n",
    "\n",
    "The next steps are:\n",
    "\n",
    "1. Choose features $x_i$ that may characterize anomalous examples  \n",
    "2. Fit paramters \n",
    "\n",
    "$\\mu_i = \\frac{1}{m} \\sum^m_{i =1} x_j^{(i)}$  \n",
    "$\\sigma_j^2 = \\frac{1}{m} \\sum^m_{i =1} (x_j^{(i)} - \\mu_j )^2$\n",
    "\n",
    "3. Given new example $x$ compute $p(x)$:\n",
    "\n",
    "$p(x) = \\prod_{j = i}^n p(x_j; \\mu_j; \\sigma_j^2) = \\prod_{j = i}^n \\frac{1}{\\sqrt{2\\pi}\\sigma_j} exp (- \\frac{(x_j - \\mu_j )^2}{2\\sigma_j^2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating anomaly detection systems\n",
    "\n",
    "In order to evaluate our models and take decisions on whether / how to improve them, we will resort to using labeled data and treat it as a supervised learning problem. \n",
    "\n",
    "A good _rule of thumb_ data split to evaluate an algorithm an algorithm would be:\n",
    "\n",
    "* **Training set**: 60% only normal data\n",
    "* **Cross-validaton**: 20% of normal data + 50% of anomalous data\n",
    "* **Test**: 20% of normal data + 50% of anomalous data\n",
    "\n",
    "Now, we can evaluate it by:\n",
    "\n",
    "1. Fitting model $p(x)$ on training set\n",
    "2. On a CV / test example, predict y if $p(x) < \\epsilon$ (anomaly) and y = 0 otherwise\n",
    "3. Using possible evaluation metrics:\n",
    "        - True pos, false pos, true neg, false neg\n",
    "        - Precision / Recall\n",
    "        - F1 score\n",
    "        \n",
    "**Note**: We can also choose $\\epsilon$ based on CV set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting question: why don't we use supervised learning (e.g. LR) directly on anomaly detection problems?\n",
    "\n",
    "Some of the reasons might be:\n",
    "\n",
    "* Strong imbalance in number of negative (normal) vs. positive examples in anomaly detection\n",
    "* Hard to learn what constitute a positive example (anomaly) as new anomaly can be substantially different from previous ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection\n",
    "\n",
    "Altough our algorithms may work well even with non-gaussian features, it is usually good practice to try and transform features to make them closer to a normal distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
